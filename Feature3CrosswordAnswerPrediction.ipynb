{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef3a42e-e018-427f-8227-fe1dc8f3da69",
   "metadata": {},
   "source": [
    "## Brainstorm/Outline\n",
    "- Goal is to fine-tune a base model LLM to predict crossword answers using Hint **and** Answer Length.\n",
    "    - Also would like to try building a NN from scratch, but compute resources are an issue.  \n",
    "- One Future Idea:\n",
    "    - Utilize hint classification: Separate Hints by type.\n",
    "        - ie.) Use a masked language model for fill in the blank hints.\n",
    "        - ie.) Train separate model for understanding puns, anagrams, wordplay, cryptic clues\n",
    "- What type of NLP task is this?\n",
    "    - This is Text2Text Generation. We have an input --> output format. We want the model to generate text based on the input.\n",
    "- What base model are we using for fine-tuning? **Google's t5-base**\n",
    "    -  Full name + Creator: T5 Text-to-Text Transfer Transformer. Made by google.\n",
    "    -  Key Characteristics\n",
    "        - Treats every NLP task as a text-to-text problem. Both the input and output are texts, regardless of task.\n",
    "            - Text-to-Text Transfer: A model that converts one piece of text into another for any NLP task.\n",
    "        - Based on Transfer Learning.\n",
    "            - Transfer Learning: Allows a model to leverage learned from one task/domain to improve performance on other.\n",
    "            - Analogy:\n",
    "                - Imagine a person who already speaks Spanish learning Italian. Since the languages are similar, they can learn faster compared to someone starting from zero.\n",
    "                -  Similarly, T5 has already learned about words, sentence structure, and general knowledge, so it adapts to crosswords faster than a randomly initialized model.\n",
    "        - Archtiecture: Sequence-to-Sequence (Encoder-Decoder Transformer).\n",
    "            - A model where an input sequence is mapped to an output sequence. Useful for when input and outputs are variable lengths.\n",
    "            - Encoder: Reads input (clue), converts it to some meaningful numerical representation.\n",
    "            - Decoder: Uses that information to generate the correct answer one token at a time.\n",
    "        - Pre-trained on massive dataset (the C4 Colossal Clean Crawled Corpus), meaning it already has built-in knowledge. Knows general facts, common words. Understands word relationships, synonyms and meaning. Understands grammar, sentence structure and phrasing\n",
    "    - How was it trained?\n",
    "        - Instead of predicting single masked tokens (like BERT), T5 masks entire spans/chunks of words and asks models to reconstruct the,  \n",
    "    -  Why is it useful for answer prediction?\n",
    "        - Understand clues by encoding them into a numerical representation.  \n",
    "        - It's text-to-text approach ensures we aren't just choosing/classifying from predefined answer - model actually learns to generate the correct words based on patterns it has seen.\n",
    "        - Pretraining on large data helps it understand word relationships, trivia and definitions.\n",
    "    - Drawbacks/Cons:\n",
    "        - Requires more compute than basic shallow learning classification models.\n",
    "        - Generative aspect means it may hallucinate/make up stuff.\n",
    "        - Does not have up-to-date knowledge. C4 datasets stops at 2019/2020.\n",
    "        - Does not store facts directly/have explicity world knowledge like a database.\n",
    "        - Does not inherently understand wordplay or anagrams.\n",
    "- General approach\n",
    "    - Fine-tune the model on crossword answers.\n",
    "    - Generate multiple answer using **Beam Search** to produce diverse, high-quality alternative answers. Also could use top-k sampling for more diversity/randomness.\n",
    "        - Necessary so we can match answer length.\n",
    "        - How beam search works: Instead of greedily picking best answer at all steps, Beam Search keeps track of multiple possible output and ranks them. Keeps the top beam_size candidates at each step.\n",
    "    - Filter answer candiadtes by length to ensure predicted output actually matches the crossword answer length. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038a16e-b54d-4085-8db9-655a89e47c89",
   "metadata": {},
   "source": [
    "## Prototype: Start with training only on 2021 crosswords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def41538-81e2-4b0c-866e-9f7656e4b3f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60ec64-c60f-4bf4-a322-287455b7c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e62d6c-a763-4448-9abf-4584bab7d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load 2021 data\n",
    "df = pd.read_csv('deep_learning_nytcrosswords2021.csv')\n",
    "\n",
    "#Rename columns for clarity\n",
    "df.rename(columns={\n",
    "    \"Word\": \"Answer\",\n",
    "    \"Clue\": \"Hint\",\n",
    "    \"Character Count\": \"Answer_Length\"\n",
    "}, inplace=True)\n",
    "\n",
    "#Reorder columns for clarity \n",
    "df = df[['Date', 'Hint', 'Answer', 'Answer_Length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e70d0-1a1e-426d-bd62-0edfe2246c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look. \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3812a-4f6d-4e96-bae9-3a6bd88e074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimal preprocessing required. t5 tokenizer is pretty advanced.\n",
    "def clean_text(text):\n",
    "    \"\"\"Minimal cleaning for T5: normalizes quotes, removes special symbols.\"\"\"\n",
    "    text = text.strip() #remove leading and trailing spaces\n",
    "    text = re.sub(r'[“”‘’]', '\"', text)  # Normalize quotes\n",
    "    text = re.sub(r'[•◇➤]', '', text)  # Remove special symbols\n",
    "    text = text.replace(\"’\", \"'\")  # Normalize apostrophes\n",
    "    return text\n",
    "    \n",
    "def add_length_to_clue(df):\n",
    "    \"\"\"\n",
    "    Appends the answer length to the clue in parentheses.\n",
    "    Assumes the dataframe has 'Clue' and 'Answer_Length' columns.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original dataframe\n",
    "    df[\"Formatted Hint\"] = df.apply(lambda row: f\"{row['Hint']} ({row['Answer_Length']})\", axis=1)\n",
    "    return df\n",
    "\n",
    "df[\"Answer\"] = df[\"Answer\"].apply(clean_text)\n",
    "df = add_length_to_clue(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b90c2ca-4d0b-4931-9033-150d9947c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small experimental preprocessing step: Add a column that classifies Hint as fill in the blank or not.\n",
    "def classify_clue_type(hint):\n",
    "    \"\"\"Returns 1 if clue is fill-in-the-blank, else 0.\"\"\"\n",
    "    return 1 if \"_\" in hint else 0\n",
    "\n",
    "# Add binary classification column\n",
    "df[\"Fill-in-the-Blank\"] = df[\"Hint\"].apply(classify_clue_type)\n",
    "\n",
    "#Reorder cols for clarity \n",
    "df = df[[\"Date\", \"Hint\", \"Formatted Hint\", \"Answer\", \"Answer_Length\", \"Fill-in-the-Blank\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abcfc49-2975-407f-a757-fbeb4b5f04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eead15d-9d8c-4dc7-b364-9461176c713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('feature3_cleaned2021_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e2230-8156-4b0a-97d6-768f0633f87f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8acc0ef-0c93-4cf9-9476-f257816701e4",
   "metadata": {},
   "source": [
    "### Training Process Explained\n",
    "- Input: Formatted Clue\n",
    "- Output: Answer\n",
    "- Tokenizer: Must use T5Tokenizer to match T5 model.\n",
    "- Imports\n",
    "    - Tokenizer: Must use T5Tokenizer to match T5 model.\n",
    "    - ConditionalGeneration: Instead of generating free text from scratch, T5 generates output based on givin input condition.\n",
    "    - Trainer: Handles batching + gradient updates etc\n",
    "    - TrainingArguments - Specificies training hyperparameters (batch size, epochs, evaluation strategy)\n",
    "    - DataCollatorForSeqtoSeq - Ensures batch sequences are properly padded for sequence-sequence learning.\n",
    "- Convert to Hugging Face Dataset\n",
    "    - What is it?  A structured dataset format used by the Hugging Face `datasets` library, optimized for efficient tokenization and training.  \n",
    "    - Why?  It allows for easy preprocessing, batching, and integration with Hugging Face’s `Trainer` API, making training faster and more memory-efficient.  \n",
    "    - Hugging Face .map() function: apply a transformation to every example in a dataset. It is highly efficient because it supports batch processing, multiprocessing, and in-place modifications.\n",
    "- Preprocessing\n",
    "    - Add prefix --> Crossword clue: {clue}. T5 is designed for task-based learning. Prefixes helps it distinguish/affirm task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774322a8-6faf-4188-80cc-38b77f43e749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/scottml/seansal2/.conda/envs/ml-rsrch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Load in cleaned data and imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_csv('feature3_cleaned2021_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8628e8a6-f212-4322-ab23-1a5278236f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch detects GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch detects GPUs:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c866ed2d-eab3-4ff9-b654-fabde5a4bd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Set up GPU training\n",
    "#Check if GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\") # Initialize Tokenizer and load in model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3448d3-680a-4ef1-8767-23acbd5439a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#Initialize Tokenizer and load in model. \n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\").to(device)\n",
    "print(\"Model and tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f710439-4b33-427e-8028-69e764dd32c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_data at 0x14e209055300> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████████████████| 23420/23420 [00:02<00:00, 10928.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'Date', 'Hint', 'Formatted Hint', 'Answer', 'Answer_Length', 'Fill-in-the-Blank', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 23420\n",
      "})\n",
      "{'Unnamed: 0': [0, 1, 2], 'Date': ['2021-10-25', '2021-01-27', '2021-08-12'], 'Hint': ['Eyelid affliction', '\"I only got a seventh-grade education, but I have a doctorate in ___\": James Brown', 'Warmer in the winter'], 'Formatted Hint': ['Eyelid affliction (4)', '\"I only got a seventh-grade education, but I have a doctorate in ___\": James Brown (4)', 'Warmer in the winter (5)'], 'Answer': ['STYE', 'FUNK', 'COCOA'], 'Answer_Length': [4, 4, 5], 'Fill-in-the-Blank': [0, 1, 0], 'input_ids': [[9172, 8130, 3, 4127, 2176, 1575, 3, 10820, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [96, 196, 163, 530, 3, 9, 17353, 18, 6801, 1073, 6, 68, 27, 43, 3, 9, 2472, 342, 16, 3, 834, 834, 834, 121, 10, 2549, 3899, 3, 10820, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [18171, 49, 16, 8, 2265, 3, 15757, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[180, 12016, 427, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [26280, 439, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2847, 5911, 188, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess + tokenize data. Convert to HuggingFace Dataset.\n",
    "def preprocess_data(examples):\n",
    "    \"\"\"Tokenizes clues and answers for T5 training.\"\"\"\n",
    "    model_inputs = tokenizer(examples[\"Formatted Hint\"], truncation=True, max_length=128, padding=\"max_length\")\n",
    "    labels = tokenizer(examples[\"Answer\"], truncation=True, max_length=32, padding=\"max_length\").input_ids\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "    \n",
    "#Convert to Hugging Face Dataset \n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "#View dataset\n",
    "print(dataset)\n",
    "\n",
    "# Show first few rows\n",
    "print(dataset[:3])  # Retrieves first 5 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffcba4e-a651-43ec-b365-970b6ad5d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 21078\n",
      "Test dataset size: 2342\n"
     ]
    }
   ],
   "source": [
    "#Split into training and testing sets\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7568c288-9ec0-487c-a94a-16223963fb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /projectnb/ds340/students/seansal2/CrosswordHelper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dd4f51-747d-4ca9-b74c-971703071e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/2821841.1.l40s/ipykernel_2632899/657530754.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13175' max='13175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13175/13175 17:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.350984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.336866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.329570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.325087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.323777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model saved to: /projectnb/ds340/students/seansal2/CrosswordHelper/t5_crossword_model\n"
     ]
    }
   ],
   "source": [
    "#TRAIN THE MODEL\n",
    "# Training arguments\n",
    "output_path = \"/projectnb/ds340/students/seansal2/CrosswordHelper/t5_crossword_model\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_path,  # Save model here\n",
    "    logging_dir=f\"{output_path}/logs\",  # Ensure logs persist\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=500,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,  # Enables mixed precision for efficiency\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save model & tokenizer to the correct directory\n",
    "model.save_pretrained(output_path)\n",
    "tokenizer.save_pretrained(output_path)\n",
    "\n",
    "print(f\"Training complete. Model saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d57e73-c597-47fa-9dc2-3e62fd5f4917",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22863618-fd8f-4ad3-a7b8-ea26e2569d9a",
   "metadata": {},
   "source": [
    "- Check Model Predictions\n",
    "- Evaluate model using other loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8172829c-57fd-4f6b-8d1b-cc1a337856f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in trained model\n",
    "output_path = \"/projectnb/ds340/students/seansal2/CrosswordHelper/t5_crossword_model\"\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(output_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e385a0a-d9dd-4797-8f4d-f96b46cc1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create one case generate_answer function using beam search \n",
    "    #One concern: should we filter to fixed length at generation or after?\n",
    "def generate_answer(clue, model, tokenizer, max_length=32, num_beams=7, top_k = 5):\n",
    "    \"\"\"\n",
    "    Generates an answer for a given crossword clue using the trained model.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    # Ensure everything runs on the same device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to the correct device\n",
    "\n",
    "    \n",
    "    input_text = clue\n",
    "    #If we add a Prefix, use this ...\n",
    "    #input_text = f\"Crossword clue: {clue}\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\" if torch.cuda.is_available() else \"cpu\") #tokenize input \n",
    "\n",
    "    #Generate text using hugging face generate text\n",
    "        #Our decoding method is beam search: instead of just greedily returning highest word probability, keep num_beams most likely choices \n",
    "    with torch.no_grad(): #Disable gradient calculation for efficiency - don't need it for inference/prediction/generation\n",
    "        #beam search, return k best answers:\n",
    "            #Could also try top-k sampling for more diverse answer\n",
    "            #Lower temperature = more structured predictions\n",
    "            #top-p/nucleus-sampling - choose words from top X% probability mass dynamically. Less random than top-k, more than beam search\n",
    "        outputs = model.generate(\n",
    "            input_ids, \n",
    "            max_length=max_length, \n",
    "            num_beams=num_beams,  # More beams = better search\n",
    "            num_return_sequences=top_k,  \n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    #Lastly convert token ids to readable text\n",
    "    predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf13c472-611d-4373-a1db-8889920428ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clue: Capital of France (5)\n",
      "Predicted Answer: ['LYON', 'FRANCE', 'CAMBOY', 'ANGELES', 'LESTIN']\n",
      "\n",
      "Clue: ___ the Explorer (4)\n",
      "Predicted Answer: ['ENTR', 'EYES', 'IERO', 'NETWORK', 'TERR']\n",
      "\n",
      "Clue: Largest planet in the solar system (7)\n",
      "Predicted Answer: ['AURORA', 'GREENPOINT', 'GREENPOOL', 'GREENHOUSE', 'GREENPOLE']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Some test cases\n",
    "clues = [\n",
    "    \"Capital of France (5)\",  \n",
    "    \"___ the Explorer (4)\",  \n",
    "    \"Largest planet in the solar system (7)\"\n",
    "]\n",
    "\n",
    "for clue in clues:\n",
    "    answer = generate_answer(clue, model, tokenizer)\n",
    "    print(f\"Clue: {clue}\")\n",
    "    print(f\"Predicted Answer: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f128a82f-da70-464b-941f-7dd447a154f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Top-5 Accuracy on 1000 test samples: 5.90%\n"
     ]
    }
   ],
   "source": [
    "#Raw Accuracy Evaluation\n",
    "num_samples = 1000  # Adjust based on test set size\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for example in test_dataset.select(range(num_samples)):\n",
    "    clue = example[\"Formatted Hint\"]  # Ensure correct column name\n",
    "    true_answer = example[\"Answer\"].strip().upper()  # Normalize answer case\n",
    "    \n",
    "    predicted_answers = generate_answer(clue, model, tokenizer)  # Returns a list\n",
    "    \n",
    "    # Check if the correct answer is in the list of predicted answers\n",
    "    if true_answer in [ans.strip().upper() for ans in predicted_answers]:\n",
    "        correct += 1\n",
    "    \n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Model Top-5 Accuracy on {num_samples} test samples: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25f1a0a8-ca5a-4e71-a40b-d1302feb4763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.3133,\n",
       "  'grad_norm': 0.6222014427185059,\n",
       "  'learning_rate': 4.50853889943074e-06,\n",
       "  'epoch': 4.554079696394687,\n",
       "  'step': 12000},\n",
       " {'loss': 0.304,\n",
       "  'grad_norm': 0.5957279205322266,\n",
       "  'learning_rate': 2.618595825426945e-06,\n",
       "  'epoch': 4.743833017077799,\n",
       "  'step': 12500},\n",
       " {'loss': 0.3096,\n",
       "  'grad_norm': 0.6870908141136169,\n",
       "  'learning_rate': 7.324478178368121e-07,\n",
       "  'epoch': 4.933586337760911,\n",
       "  'step': 13000},\n",
       " {'eval_loss': 0.32377704977989197,\n",
       "  'eval_runtime': 3.721,\n",
       "  'eval_samples_per_second': 629.405,\n",
       "  'eval_steps_per_second': 78.743,\n",
       "  'epoch': 5.0,\n",
       "  'step': 13175},\n",
       " {'train_runtime': 1044.8926,\n",
       "  'train_samples_per_second': 100.862,\n",
       "  'train_steps_per_second': 12.609,\n",
       "  'total_flos': 1.60445180215296e+16,\n",
       "  'train_loss': 0.36967294074100154,\n",
       "  'epoch': 5.0,\n",
       "  'step': 13175}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history[-5:]  # Last 5 logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3b61a-07f9-4d7c-8604-a1896845afa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
